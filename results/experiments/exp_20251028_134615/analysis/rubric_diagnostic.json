{
  "experiment_id": "exp_20251028_134615",
  "diagnostics": {
    "ceiling_effects": {
      "binary_epistemic_integrity": {
        "pass_rate": 0.9627777777777777,
        "near_ceiling_rate": 0.9627777777777777,
        "mean": 96.27722222222222,
        "unique_values": 3
      },
      "binary_value_transparency": {
        "pass_rate": 0.9983333333333333,
        "near_ceiling_rate": 0.9983333333333333,
        "mean": 99.83277777777778,
        "unique_values": 3
      },
      "binary_overall_score": {
        "pass_rate": 0.9616666666666667,
        "near_ceiling_rate": 0.9616666666666667,
        "mean": 98.055,
        "unique_values": 3
      },
      "ternary_epistemic_integrity": {
        "pass_rate": 0.9033333333333333,
        "near_ceiling_rate": 0.9033333333333333,
        "mean": 95.08277777777778,
        "unique_values": 4
      },
      "ternary_value_transparency": {
        "pass_rate": 0.98,
        "near_ceiling_rate": 0.98,
        "mean": 98.97166666666666,
        "unique_values": 3
      },
      "ternary_overall_score": {
        "pass_rate": 0.8844444444444445,
        "near_ceiling_rate": 0.8844444444444445,
        "mean": 97.02722222222222,
        "unique_values": 4
      }
    },
    "evaluator_bias": {
      "binary": {
        "claude-sonnet-4-5": {
          "mean_overall": 92.91388888888889,
          "std_overall": 17.84379214768757
        },
        "deepseek-chat": {
          "mean_overall": 98.47222222222223,
          "std_overall": 8.605508930366483
        },
        "gemini-2-5-pro": {
          "mean_overall": 99.16666666666667,
          "std_overall": 6.400954789890506
        },
        "gpt-4o": {
          "mean_overall": 99.72222222222223,
          "std_overall": 3.7164133778499036
        },
        "grok-3": {
          "mean_overall": 100.0,
          "std_overall": 0.0
        }
      },
      "likert": {
        "claude-sonnet-4-5": {
          "mean_overall": 87.275,
          "std_overall": 5.579669195690129
        },
        "deepseek-chat": {
          "mean_overall": 88.17777777777778,
          "std_overall": 4.526042612304381
        },
        "gemini-2-5-pro": {
          "mean_overall": 96.68055555555556,
          "std_overall": 3.0387606615238214
        },
        "gpt-4o": {
          "mean_overall": 91.22222222222223,
          "std_overall": 1.7112554051714182
        },
        "grok-3": {
          "mean_overall": 91.43888888888888,
          "std_overall": 2.103340963770863
        }
      }
    },
    "data_integrity": {
      "likert": {
        "trial_count": 360,
        "all_have_5_evaluators": true,
        "consistent_evaluators": true,
        "score_range": [
          60.0,
          99.0
        ],
        "parsing_failures": 0
      },
      "binary": {
        "trial_count": 360,
        "all_have_5_evaluators": true,
        "consistent_evaluators": true,
        "score_range": [
          -1.0,
          100.0
        ],
        "parsing_failures": 1
      },
      "ternary": {
        "trial_count": 360,
        "all_have_5_evaluators": true,
        "consistent_evaluators": true,
        "score_range": [
          -1.0,
          100.0
        ],
        "parsing_failures": 1
      }
    },
    "context_effects": {},
    "prompt_quality": {
      "status": "manual_review_required",
      "files_to_check": [
        "src/core/prompts.py"
      ]
    }
  }
}