{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensional Structure Validation Analysis\n",
    "\n",
    "**Week 1, Task 4 (Analysis 1.4) of Analysis & Publication Plan**\n",
    "\n",
    "**Research Question:** Are Epistemic Integrity and Value Transparency independent dimensions, or are they redundant (highly correlated)?\n",
    "\n",
    "**Dataset:** 1,800 evaluations (360 trials √ó 5 evaluators)\n",
    "\n",
    "**Purpose:**\n",
    "1. Test if 2-dimensional rubric design is justified\n",
    "2. Identify evaluators who conflate dimensions\n",
    "3. Validate that dimensions capture distinct aspects of reasoning quality\n",
    "\n",
    "**Independence Criterion:**\n",
    "- **Target:** r < 0.60 (Cohen's threshold for \"not redundant\")\n",
    "- **PCA Target:** 2 dimensions should capture >90% variance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from analysis.dimensional_analysis import DimensionalAnalyzer\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Experiment ID\n",
    "EXPERIMENT_ID = 'exp_20251028_134615'\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Run Analysis\n",
    "\n",
    "This uses the `dimensional_analysis.py` script to:\n",
    "- Load Likert evaluation data (360 trials √ó 5 evaluators = 1,800 evaluations)\n",
    "- Calculate correlation between Epistemic Integrity and Value Transparency\n",
    "- Test dimensional independence (target: r < 0.60)\n",
    "- Perform PCA to validate 2D structure\n",
    "- Identify evaluators who conflate dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete analysis\n",
    "analyzer = DimensionalAnalyzer(EXPERIMENT_ID)\n",
    "results = analyzer.analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key results\n",
    "independence = results['independence_test']\n",
    "pca_results = results['pca']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DIMENSIONAL STRUCTURE VALIDATION: KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. OVERALL DIMENSIONAL CORRELATION\")\n",
    "print(\"-\"*70)\n",
    "print(f\"   Pearson r: {independence['overall_correlation']['r']:.3f}\")\n",
    "print(f\"   95% CI: [{independence['overall_correlation']['ci_lower']:.3f}, {independence['overall_correlation']['ci_upper']:.3f}]\")\n",
    "print(f\"   p-value: {independence['overall_correlation']['p']:.6f}\")\n",
    "print(f\"   n: {independence['overall_correlation']['n']:,}\")\n",
    "\n",
    "print(f\"\\n   Independence Test: r < {independence['threshold']:.2f}\")\n",
    "if independence['dimensions_independent']:\n",
    "    print(f\"   ‚úÖ PASS: Dimensions are sufficiently independent\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è BORDERLINE/FAIL: Dimensions show moderate-to-high correlation\")\n",
    "\n",
    "print(f\"\\n   {independence['interpretation']}\")\n",
    "\n",
    "print(\"\\n2. PCA VARIANCE DECOMPOSITION\")\n",
    "print(\"-\"*70)\n",
    "print(f\"   PC1: {pca_results['variance_explained']['PC1']*100:.1f}%\")\n",
    "print(f\"   PC2: {pca_results['variance_explained']['PC2']*100:.1f}%\")\n",
    "print(f\"   Cumulative: {pca_results['variance_explained']['cumulative']*100:.1f}%\")\n",
    "\n",
    "if pca_results['variance_explained']['cumulative'] > 0.90:\n",
    "    print(f\"\\n   ‚úÖ Two dimensions capture {pca_results['variance_explained']['cumulative']*100:.1f}% variance\")\n",
    "    print(f\"      2D rubric structure is justified\")\n",
    "else:\n",
    "    print(f\"\\n   ‚ö†Ô∏è Two dimensions capture only {pca_results['variance_explained']['cumulative']*100:.1f}% variance\")\n",
    "    print(f\"      Additional dimensions may be present\")\n",
    "\n",
    "print(\"\\n3. EVALUATOR-SPECIFIC PATTERNS\")\n",
    "print(\"-\"*70)\n",
    "conflaters = results['dimension_conflaters']\n",
    "if conflaters:\n",
    "    print(f\"   ‚ö†Ô∏è {len(conflaters)} evaluator(s) conflate dimensions (r > 0.70):\")\n",
    "    for evaluator in conflaters:\n",
    "        r_value = independence['per_evaluator'][evaluator]['r']\n",
    "        print(f\"      - {evaluator}: r={r_value:.3f}\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ No evaluators conflate dimensions (all r < 0.70)\")\n",
    "    print(f\"      All evaluators distinguish Epistemic Integrity from Value Transparency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 1: Scatter Plot - Overall Dimensional Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataframe for visualization\n",
    "df = analyzer.build_dataframe()\n",
    "\n",
    "# Create scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot all evaluations\n",
    "ax.scatter(\n",
    "    df['epistemic_integrity'],\n",
    "    df['value_transparency'],\n",
    "    alpha=0.3,\n",
    "    s=20,\n",
    "    c='steelblue',\n",
    "    edgecolors='none'\n",
    ")\n",
    "\n",
    "# Add regression line\n",
    "z = np.polyfit(df['epistemic_integrity'], df['value_transparency'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(df['epistemic_integrity'].min(), df['epistemic_integrity'].max(), 100)\n",
    "ax.plot(x_line, p(x_line), \"r--\", linewidth=2, alpha=0.8, label=f\"r={independence['overall_correlation']['r']:.3f}\")\n",
    "\n",
    "# Styling\n",
    "ax.set_xlabel('Epistemic Integrity Score', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Value Transparency Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Dimensional Relationship: Epistemic Integrity √ó Value Transparency', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='lower right')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(40, 105)\n",
    "ax.set_ylim(40, 105)\n",
    "\n",
    "# Add diagonal reference line (perfect correlation)\n",
    "ax.plot([40, 105], [40, 105], 'k:', linewidth=1, alpha=0.3, label='y=x (perfect correlation)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Correlation: r={independence['overall_correlation']['r']:.3f}\")\n",
    "print(f\"üìä Closer to diagonal (y=x) = higher correlation\")\n",
    "print(f\"üìä More scatter = lower correlation = more independent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 2: Per-Evaluator Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for each evaluator\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "evaluators = sorted(df['evaluator'].unique())\n",
    "colors = sns.color_palette('husl', len(evaluators))\n",
    "\n",
    "for idx, evaluator in enumerate(evaluators):\n",
    "    if idx >= len(axes):\n",
    "        break\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    eval_df = df[df['evaluator'] == evaluator]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(\n",
    "        eval_df['epistemic_integrity'],\n",
    "        eval_df['value_transparency'],\n",
    "        alpha=0.5,\n",
    "        s=30,\n",
    "        c=[colors[idx]],\n",
    "        edgecolors='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    \n",
    "    # Regression line\n",
    "    if len(eval_df) >= 10:\n",
    "        z = np.polyfit(eval_df['epistemic_integrity'], eval_df['value_transparency'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_line = np.linspace(eval_df['epistemic_integrity'].min(), eval_df['epistemic_integrity'].max(), 100)\n",
    "        ax.plot(x_line, p(x_line), \"r--\", linewidth=2, alpha=0.8)\n",
    "    \n",
    "    # Get correlation\n",
    "    eval_corr = independence['per_evaluator'][evaluator]\n",
    "    \n",
    "    # Title with correlation\n",
    "    warning = \" ‚ö†Ô∏è\" if eval_corr['r'] > 0.70 else \"\"\n",
    "    ax.set_title(f\"{evaluator}\\nr={eval_corr['r']:.3f}{warning}\", fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Epistemic Integrity', fontsize=9)\n",
    "    ax.set_ylabel('Value Transparency', fontsize=9)\n",
    "    ax.set_xlim(40, 105)\n",
    "    ax.set_ylim(40, 105)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# Hide unused subplot\n",
    "if len(evaluators) < len(axes):\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "plt.suptitle('Per-Evaluator Dimensional Correlations', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä ‚ö†Ô∏è indicates evaluator conflating dimensions (r > 0.70)\")\n",
    "print(\"üìä Steeper/tighter scatter = higher correlation = more conflation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 3: Per-Evaluator Correlation Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract per-evaluator correlations\n",
    "eval_corrs = []\n",
    "for evaluator, stats in sorted(independence['per_evaluator'].items(), key=lambda x: x[1]['r'], reverse=True):\n",
    "    eval_corrs.append({\n",
    "        'Evaluator': evaluator,\n",
    "        'r': stats['r'],\n",
    "        'Conflates': stats['r'] > 0.70\n",
    "    })\n",
    "\n",
    "df_eval_corrs = pd.DataFrame(eval_corrs)\n",
    "\n",
    "# Create bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = ['red' if conflate else 'steelblue' for conflate in df_eval_corrs['Conflates']]\n",
    "\n",
    "bars = ax.barh(\n",
    "    df_eval_corrs['Evaluator'],\n",
    "    df_eval_corrs['r'],\n",
    "    color=colors,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "for bar, r_val in zip(bars, df_eval_corrs['r']):\n",
    "    ax.text(\n",
    "        r_val + 0.01,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f'{r_val:.3f}',\n",
    "        ha='left',\n",
    "        va='center',\n",
    "        fontweight='bold',\n",
    "        fontsize=11\n",
    "    )\n",
    "\n",
    "# Reference lines\n",
    "ax.axvline(x=0.60, color='orange', linestyle='--', linewidth=2, alpha=0.7, label='Independence threshold (r=0.60)')\n",
    "ax.axvline(x=0.70, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Conflation threshold (r=0.70)')\n",
    "\n",
    "# Styling\n",
    "ax.set_title('Evaluator Dimensional Correlations', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Correlation (Epistemic Integrity √ó Value Transparency)', fontsize=11)\n",
    "ax.set_xlim(0, 1.0)\n",
    "ax.legend(fontsize=10, loc='lower right')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Red bars: Evaluators conflating dimensions (r > 0.70)\")\n",
    "print(\"üìä Blue bars: Evaluators distinguishing dimensions adequately\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization 4: PCA Biplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA for visualization\n",
    "trial_means = df.groupby('trial_id')[['epistemic_integrity', 'value_transparency']].mean()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(trial_means)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create biplot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot transformed data points\n",
    "ax.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.3, s=30, c='steelblue', edgecolors='none')\n",
    "\n",
    "# Plot loading vectors\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "# Scale loadings for visibility\n",
    "scale = 3.0\n",
    "ax.arrow(0, 0, loadings[0, 0]*scale, loadings[0, 1]*scale, \n",
    "         head_width=0.3, head_length=0.3, fc='red', ec='red', linewidth=2, alpha=0.8)\n",
    "ax.text(loadings[0, 0]*scale*1.15, loadings[0, 1]*scale*1.15, \n",
    "        'Epistemic\\nIntegrity', fontsize=11, fontweight='bold', ha='center', color='red')\n",
    "\n",
    "ax.arrow(0, 0, loadings[1, 0]*scale, loadings[1, 1]*scale, \n",
    "         head_width=0.3, head_length=0.3, fc='green', ec='green', linewidth=2, alpha=0.8)\n",
    "ax.text(loadings[1, 0]*scale*1.15, loadings[1, 1]*scale*1.15, \n",
    "        'Value\\nTransparency', fontsize=11, fontweight='bold', ha='center', color='green')\n",
    "\n",
    "# Styling\n",
    "ax.set_xlabel(f'PC1 ({pca_results[\"variance_explained\"][\"PC1\"]*100:.1f}% variance)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel(f'PC2 ({pca_results[\"variance_explained\"][\"PC2\"]*100:.1f}% variance)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('PCA Biplot: Dimensional Structure', fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=0, color='k', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "ax.axvline(x=0, color='k', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Red arrow: Epistemic Integrity direction in PC space\")\n",
    "print(\"üìä Green arrow: Value Transparency direction in PC space\")\n",
    "print(\"üìä Angle between arrows indicates correlation:\")\n",
    "print(\"   - 90¬∞ = independent (r‚âà0)\")\n",
    "print(\"   - 0¬∞ = perfectly correlated (r=1)\")\n",
    "print(\"   - 180¬∞ = negatively correlated (r=-1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PCA INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nVariance Explained:\")\n",
    "print(f\"  PC1: {pca_results['variance_explained']['PC1']*100:.1f}%\")\n",
    "print(f\"  PC2: {pca_results['variance_explained']['PC2']*100:.1f}%\")\n",
    "print(f\"  Total: {pca_results['variance_explained']['cumulative']*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nPC1 Loadings (dominant component):\")\n",
    "print(f\"  Epistemic Integrity: {pca_results['loadings']['PC1']['epistemic_integrity']:+.3f}\")\n",
    "print(f\"  Value Transparency:  {pca_results['loadings']['PC1']['value_transparency']:+.3f}\")\n",
    "\n",
    "print(f\"\\nPC2 Loadings (secondary component):\")\n",
    "print(f\"  Epistemic Integrity: {pca_results['loadings']['PC2']['epistemic_integrity']:+.3f}\")\n",
    "print(f\"  Value Transparency:  {pca_results['loadings']['PC2']['value_transparency']:+.3f}\")\n",
    "\n",
    "print(f\"\\n{pca_results['interpretation']['interpretation']}\")\n",
    "\n",
    "# Additional interpretation\n",
    "ei_loading = abs(pca_results['loadings']['PC1']['epistemic_integrity'])\n",
    "vt_loading = abs(pca_results['loadings']['PC1']['value_transparency'])\n",
    "loading_diff = abs(ei_loading - vt_loading)\n",
    "\n",
    "if loading_diff < 0.1:\n",
    "    print(\"\\nüí° PC1 loads equally on both dimensions ‚Üí General quality factor\")\n",
    "    print(\"   Both dimensions contribute similarly to overall variance\")\n",
    "elif ei_loading > vt_loading:\n",
    "    print(\"\\nüí° PC1 loads more heavily on Epistemic Integrity\")\n",
    "    print(\"   Epistemic Integrity drives more variance than Value Transparency\")\n",
    "else:\n",
    "    print(\"\\nüí° PC1 loads more heavily on Value Transparency\")\n",
    "    print(\"   Value Transparency drives more variance than Epistemic Integrity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### Primary Findings\n",
    "\n",
    "**1. Dimensional Independence Test**\n",
    "\n",
    "[Results will be filled in based on analysis above]\n",
    "\n",
    "**If r < 0.60:**\n",
    "- ‚úÖ Dimensions are sufficiently independent\n",
    "- ‚úÖ 2D rubric design is justified\n",
    "- Epistemic Integrity and Value Transparency capture distinct aspects\n",
    "\n",
    "**If 0.60 ‚â§ r < 0.80:**\n",
    "- ‚ö†Ô∏è Dimensions show moderate-to-high correlation\n",
    "- Some redundancy exists but dimensions still provide unique information\n",
    "- 2D rubric acceptable but could potentially be simplified\n",
    "\n",
    "**If r ‚â• 0.80:**\n",
    "- ‚ùå Dimensions are highly correlated (likely redundant)\n",
    "- Consider simplifying to single dimension or redefining dimensions\n",
    "\n",
    "---\n",
    "\n",
    "### 2. PCA Validation\n",
    "\n",
    "**If 2 dimensions capture >90% variance:**\n",
    "- ‚úÖ 2D structure is validated\n",
    "- Two dimensions adequately represent the data\n",
    "- No major information loss from 2D rubric\n",
    "\n",
    "**If 2 dimensions capture <90% variance:**\n",
    "- ‚ö†Ô∏è Additional factors may be present\n",
    "- Consider: Are we missing important dimensions?\n",
    "- Or: High residual variance (noise, evaluator disagreement)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Evaluator-Specific Patterns\n",
    "\n",
    "**Evaluators conflating dimensions (r > 0.70):**\n",
    "\n",
    "[List will be populated from analysis]\n",
    "\n",
    "**Interpretation:**\n",
    "- If 0 conflaters: All evaluators distinguish dimensions adequately ‚úÖ\n",
    "- If 1-2 conflaters: Specific evaluator bias, not systemic issue\n",
    "- If 3+ conflaters: Dimensions may be inherently difficult to separate\n",
    "\n",
    "---\n",
    "\n",
    "## Implications for Research\n",
    "\n",
    "**For Human Validation (Week 2-3):**\n",
    "- If dimensions independent: Validate both dimensions separately\n",
    "- If dimensions correlated: Focus validation on overall score, de-emphasize dimension scores\n",
    "- Train annotators to distinguish epistemic vs value aspects explicitly\n",
    "\n",
    "**For Publication:**\n",
    "- If 2D justified: Report both dimensions as distinct constructs\n",
    "- If redundancy found: Acknowledge correlation, justify why both are kept\n",
    "- Document evaluator-specific conflation patterns\n",
    "\n",
    "**For Future Rubric Design:**\n",
    "- If independent: 2D rubric is effective, can be reused\n",
    "- If correlated: Consider redefining dimensions to increase independence\n",
    "- Or: Accept correlation as inherent feature of constitutional reasoning evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "**‚úÖ Week 1 Complete (All 4 Analyses Done):**\n",
    "1. Analysis 1.1: Rubric Comparison ‚Üí Likert wins\n",
    "2. Analysis 1.3: Evaluator Agreement ‚Üí Consensus scores ready\n",
    "3. Analysis 1.2: Model √ó Constitution Interaction ‚Üí Interaction detected\n",
    "4. **Analysis 1.4: Dimensional Structure ‚Üí [Results from this notebook]**\n",
    "\n",
    "**‚è≠ Week 2: Validation Design**\n",
    "- Design human validation rubric (Likert format)\n",
    "- Build validation tool (Google Sheets or web form)\n",
    "- Select 30-50 trials for validation (stratified sample)\n",
    "- Include guidance on distinguishing epistemic vs value dimensions\n",
    "\n",
    "---\n",
    "\n",
    "**Analysis Date:** 2025-10-31  \n",
    "**Experiment:** exp_20251028_134615  \n",
    "**Evaluations Analyzed:** 1,800 (360 trials √ó 5 evaluators)  \n",
    "\n",
    "**Key Question Answered:** Are Epistemic Integrity and Value Transparency independent dimensions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Constitution Project",
   "language": "python",
   "name": "constitution"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
